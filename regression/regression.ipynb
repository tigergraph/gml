{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc354491-c629-47b3-a7d6-b4b5060409de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# folder path\n",
    "dir_path = \"/home/tigergraph/GraphML/\"\n",
    "\n",
    "# list to store files\n",
    "notebook_list = []\n",
    "\n",
    "# Iterate directory\n",
    "for root, dirs, files in os.walk(dir_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".ipynb\") and \"checkpoint\" not in file and \"regression\" not in file:\n",
    "            notebook_list.append(os.path.join(root, file))\n",
    "        \n",
    "for notebook in notebook_list:\n",
    "    print(notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5249446-1e9d-4c03-a2c2-cd8d69febb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyTigerGraph import TigerGraphConnection\n",
    "\n",
    "# Read in DB configs\n",
    "with open('../config.json', \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "conn = TigerGraphConnection(\n",
    "    host=config[\"host\"],\n",
    "    username=config[\"username\"],\n",
    "    password=config[\"password\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "027412ab-fced-4f6a-be78-ef7def5e4a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory_profiler in /opt/conda/lib/python3.9/site-packages (0.61.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from memory_profiler) (5.9.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/memory_profiler.py:1136: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ipython_version = LooseVersion(IPython.__version__)\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/GNNs/PyG/gcn_link_prediction.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/GNNs/PyG && jupyter nbconvert --to html --execute gcn_link_prediction.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/GNNs/PyG/gcn_link_prediction.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook gcn_link_prediction.ipynb to html\n",
      "[NbConvertApp] Writing 662519 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/GNNs/PyG/gcn_link_prediction.ipynb/gcn_link_prediction.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.61 MiB, increment: 0.20 MiB\n",
      "The CPU usage is:  21.5\n",
      "RAM Used (GB): 7.553880064\n",
      "/home/tigergraph/GML/graph-ml-notebooks/GNNs/PyG/gcn_link_prediction.ipynb executed successfully\n",
      "execution time: 308.41598892211914 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/GNNs/PyG/gcn_node_classification.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/GNNs/PyG && jupyter nbconvert --to html --execute gcn_node_classification.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/GNNs/PyG/gcn_node_classification.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook gcn_node_classification.ipynb to html\n",
      "[NbConvertApp] Writing 683222 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/GNNs/PyG/gcn_node_classification.ipynb/gcn_node_classification.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.66 MiB, increment: 0.01 MiB\n",
      "The CPU usage is:  21.2\n",
      "RAM Used (GB): 7.539929088\n",
      "/home/tigergraph/GML/graph-ml-notebooks/GNNs/PyG/gcn_node_classification.ipynb executed successfully\n",
      "execution time: 201.66628551483154 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/GNNs/PyG/hgat_node_classification.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/GNNs/PyG && jupyter nbconvert --to html --execute hgat_node_classification.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/GNNs/PyG/hgat_node_classification.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook hgat_node_classification.ipynb to html\n",
      "[NbConvertApp] Writing 709749 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/GNNs/PyG/hgat_node_classification.ipynb/hgat_node_classification.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.68 MiB, increment: 0.00 MiB\n",
      "The CPU usage is:  21.7\n",
      "RAM Used (GB): 7.761166336\n",
      "/home/tigergraph/GML/graph-ml-notebooks/GNNs/PyG/hgat_node_classification.ipynb executed successfully\n",
      "execution time: 355.144394159317 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/GNNs/Spektral/gcn_node_classification.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/GNNs/Spektral && jupyter nbconvert --to html --execute gcn_node_classification.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/GNNs/Spektral/gcn_node_classification.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook gcn_node_classification.ipynb to html\n",
      "2023-01-04 21:19:28.487625: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-04 21:19:28.647241: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-04 21:19:28.654959: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-04 21:19:28.654982: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-04 21:19:28.694762: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-04 21:19:29.525295: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-04 21:19:29.525402: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-04 21:19:29.525414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-04 21:19:31.768213: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-04 21:19:31.768249: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-04 21:19:31.768276: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (df8d3fc244d1): /proc/driver/nvidia/version does not exist\n",
      "2023-01-04 21:19:31.768850: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[NbConvertApp] Writing 695733 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/GNNs/Spektral/gcn_node_classification.ipynb/gcn_node_classification.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.74 MiB, increment: 0.06 MiB\n",
      "The CPU usage is:  22.6\n",
      "RAM Used (GB): 7.440146432\n",
      "/home/tigergraph/GML/graph-ml-notebooks/GNNs/Spektral/gcn_node_classification.ipynb executed successfully\n",
      "execution time: 233.41414785385132 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/GNNs/DGL/gcn_node_classification.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/GNNs/DGL && jupyter nbconvert --to html --execute gcn_node_classification.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/GNNs/DGL/gcn_node_classification.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook gcn_node_classification.ipynb to html\n",
      "[NbConvertApp] Writing 707551 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/GNNs/DGL/gcn_node_classification.ipynb/gcn_node_classification.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.77 MiB, increment: 0.02 MiB\n",
      "The CPU usage is:  27.0\n",
      "RAM Used (GB): 7.50467072\n",
      "/home/tigergraph/GML/graph-ml-notebooks/GNNs/DGL/gcn_node_classification.ipynb executed successfully\n",
      "execution time: 201.00557255744934 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/GNNs/DGL/rgcn_node_classification.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/GNNs/DGL && jupyter nbconvert --to html --execute rgcn_node_classification.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/GNNs/DGL/rgcn_node_classification.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook rgcn_node_classification.ipynb to html\n",
      "[NbConvertApp] Writing 724115 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/GNNs/DGL/rgcn_node_classification.ipynb/rgcn_node_classification.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.77 MiB, increment: 0.00 MiB\n",
      "The CPU usage is:  21.8\n",
      "RAM Used (GB): 8.076378112\n",
      "/home/tigergraph/GML/graph-ml-notebooks/GNNs/DGL/rgcn_node_classification.ipynb executed successfully\n",
      "execution time: 350.3775565624237 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/algos/topologicalLinkPrediction.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/algos && jupyter nbconvert --to html --execute topologicalLinkPrediction.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/algos/topologicalLinkPrediction.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook topologicalLinkPrediction.ipynb to html\n",
      "[NbConvertApp] Writing 674799 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/algos/topologicalLinkPrediction.ipynb/topologicalLinkPrediction.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.78 MiB, increment: 0.01 MiB\n",
      "The CPU usage is:  21.9\n",
      "RAM Used (GB): 7.312748544\n",
      "/home/tigergraph/GML/graph-ml-notebooks/algos/topologicalLinkPrediction.ipynb executed successfully\n",
      "execution time: 265.50346183776855 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/algos/embedding.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/algos && jupyter nbconvert --to html --execute embedding.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/algos/embedding.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook embedding.ipynb to html\n",
      "[NbConvertApp] Writing 690624 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/algos/embedding.ipynb/embedding.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.79 MiB, increment: 0.00 MiB\n",
      "The CPU usage is:  21.8\n",
      "RAM Used (GB): 7.458516992\n",
      "/home/tigergraph/GML/graph-ml-notebooks/algos/embedding.ipynb executed successfully\n",
      "execution time: 228.1082730293274 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/algos/classification.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/algos && jupyter nbconvert --to html --execute classification.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/algos/classification.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook classification.ipynb to html\n",
      "[NbConvertApp] Writing 708898 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/algos/classification.ipynb/classification.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.80 MiB, increment: 0.01 MiB\n",
      "The CPU usage is:  21.6\n",
      "RAM Used (GB): 7.396671488\n",
      "/home/tigergraph/GML/graph-ml-notebooks/algos/classification.ipynb executed successfully\n",
      "execution time: 380.5423550605774 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/algos/similarity.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/algos && jupyter nbconvert --to html --execute similarity.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/algos/similarity.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook similarity.ipynb to html\n",
      "[NbConvertApp] Writing 657096 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/algos/similarity.ipynb/similarity.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.80 MiB, increment: 0.01 MiB\n",
      "The CPU usage is:  20.8\n",
      "RAM Used (GB): 7.334014976\n",
      "/home/tigergraph/GML/graph-ml-notebooks/algos/similarity.ipynb executed successfully\n",
      "execution time: 205.19513034820557 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/algos/centrality.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/algos && jupyter nbconvert --to html --execute centrality.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/algos/centrality.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook centrality.ipynb to html\n",
      "[NbConvertApp] Writing 764684 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/algos/centrality.ipynb/centrality.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.81 MiB, increment: 0.00 MiB\n",
      "The CPU usage is:  22.5\n",
      "RAM Used (GB): 9.964990464\n",
      "/home/tigergraph/GML/graph-ml-notebooks/algos/centrality.ipynb executed successfully\n",
      "execution time: 485.6545944213867 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/algos/community.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/algos && jupyter nbconvert --to html --execute community.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/algos/community.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook community.ipynb to html\n",
      "[NbConvertApp] Writing 706542 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/algos/community.ipynb/community.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.82 MiB, increment: 0.01 MiB\n",
      "The CPU usage is:  23.0\n",
      "RAM Used (GB): 10.02795008\n",
      "/home/tigergraph/GML/graph-ml-notebooks/algos/community.ipynb executed successfully\n",
      "execution time: 556.4984426498413 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/algos/pathfinding.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/algos && jupyter nbconvert --to html --execute pathfinding.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/algos/pathfinding.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook pathfinding.ipynb to html\n",
      "[NbConvertApp] Writing 672272 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/algos/pathfinding.ipynb/pathfinding.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.82 MiB, increment: 0.00 MiB\n",
      "The CPU usage is:  23.6\n",
      "RAM Used (GB): 10.346160128\n",
      "/home/tigergraph/GML/graph-ml-notebooks/algos/pathfinding.ipynb executed successfully\n",
      "execution time: 377.67410349845886 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/applications/recommendation/recommendation.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/applications/recommendation && jupyter nbconvert --to html --execute recommendation.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/applications/recommendation/recommendation.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook recommendation.ipynb to html\n",
      "[NbConvertApp] Writing 758920 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/applications/recommendation/recommendation.ipynb/recommendation.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.83 MiB, increment: 0.00 MiB\n",
      "The CPU usage is:  22.6\n",
      "RAM Used (GB): 7.444975616\n",
      "/home/tigergraph/GML/graph-ml-notebooks/applications/recommendation/recommendation.ipynb executed successfully\n",
      "execution time: 127.89344096183777 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/applications/fraud_detection/fraud_detection.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/applications/fraud_detection && jupyter nbconvert --to html --execute fraud_detection.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/applications/fraud_detection/fraud_detection.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook fraud_detection.ipynb to html\n",
      "[NbConvertApp] Writing 1139882 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/applications/fraud_detection/fraud_detection.ipynb/fraud_detection.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.83 MiB, increment: 0.00 MiB\n",
      "The CPU usage is:  23.4\n",
      "RAM Used (GB): 7.491518464\n",
      "/home/tigergraph/GML/graph-ml-notebooks/applications/fraud_detection/fraud_detection.ipynb executed successfully\n",
      "execution time: 330.2850160598755 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/basics/gsql_102.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/basics && jupyter nbconvert --to html --execute gsql_102.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/basics/gsql_102.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook gsql_102.ipynb to html\n",
      "[NbConvertApp] Writing 727585 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/basics/gsql_102.ipynb/gsql_102.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.83 MiB, increment: 0.00 MiB\n",
      "The CPU usage is:  21.5\n",
      "RAM Used (GB): 9.972473856\n",
      "/home/tigergraph/GML/graph-ml-notebooks/basics/gsql_102.ipynb executed successfully\n",
      "execution time: 332.4458079338074 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/basics/datasets.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/basics && jupyter nbconvert --to html --execute datasets.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/basics/datasets.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook datasets.ipynb to html\n",
      "[NbConvertApp] Writing 630515 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/basics/datasets.ipynb/datasets.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.84 MiB, increment: 0.00 MiB\n",
      "The CPU usage is:  26.7\n",
      "RAM Used (GB): 7.578284032\n",
      "/home/tigergraph/GML/graph-ml-notebooks/basics/datasets.ipynb executed successfully\n",
      "execution time: 66.88913416862488 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/basics/pyTigergraph_101.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/basics && jupyter nbconvert --to html --execute pyTigergraph_101.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/basics/pyTigergraph_101.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook pyTigergraph_101.ipynb to html\n",
      "[NbConvertApp] Writing 820049 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/basics/pyTigergraph_101.ipynb/pyTigergraph_101.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.84 MiB, increment: 0.00 MiB\n",
      "The CPU usage is:  28.8\n",
      "RAM Used (GB): 7.245090816\n",
      "/home/tigergraph/GML/graph-ml-notebooks/basics/pyTigergraph_101.ipynb executed successfully\n",
      "execution time: 125.02234935760498 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/basics/feature_engineering.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/basics && jupyter nbconvert --to html --execute feature_engineering.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/basics/feature_engineering.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook feature_engineering.ipynb to html\n",
      "[NbConvertApp] Writing 643077 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/basics/feature_engineering.ipynb/feature_engineering.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.85 MiB, increment: 0.00 MiB\n",
      "The CPU usage is:  29.4\n",
      "RAM Used (GB): 7.512264704\n",
      "/home/tigergraph/GML/graph-ml-notebooks/basics/feature_engineering.ipynb executed successfully\n",
      "execution time: 204.19608330726624 seconds\n",
      "\n",
      "Dropping all graphs, loading jobs, and queries sucessfully.\n",
      "\n",
      "Executing notebook: /home/tigergraph/GML/graph-ml-notebooks/basics/gsql_101.ipynb\n",
      "cd /home/tigergraph/GML/graph-ml-notebooks/basics && jupyter nbconvert --to html --execute gsql_101.ipynb --output-dir=/home/tigergraph/GML/graph-ml-notebooks/output/basics/gsql_101.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook gsql_101.ipynb to html\n",
      "[NbConvertApp] Writing 639089 bytes to /home/tigergraph/GML/graph-ml-notebooks/output/basics/gsql_101.ipynb/gsql_101.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 77.86 MiB, increment: 0.01 MiB\n",
      "The CPU usage is:  22.4\n",
      "RAM Used (GB): 7.32223488\n",
      "/home/tigergraph/GML/graph-ml-notebooks/basics/gsql_101.ipynb executed successfully\n",
      "execution time: 155.99732637405396 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import psutil\n",
    "!pip install memory_profiler\n",
    "%load_ext memory_profiler\n",
    "\n",
    "notebook_performance_out = '/home/tigergraph/GraphML/output/notebook_' + config[\"job_id\"] + '.csv'\n",
    "algorithm_performance_out = '/home/tigergraph/GraphML/output/algorithm_' + config[\"job_id\"] + '.csv'\n",
    "\n",
    "# notebook_header = [\"notebook_id\", \"is_failure\", \"host_cpu_usage\", \"notebook_memory\", \"execution_time\", \"host_memory\", \"error_message\", \"cron_job_id\"]\n",
    "\n",
    "# algorithm_header = [\"algorithm_id\", \"is_failure\", \"host_cpu_usage\", \"algo_memory\", \"execution_time\", \"host_memory\", \"algo_version\", \"error_message\", \"notebook_id\"]\n",
    "\n",
    "# os.makedirs(os.path.dirname(notebook_performance_out), exist_ok=True)\n",
    "# with open(notebook_performance_out, mode='a+', encoding='utf-8') as f:\n",
    "#         writer = csv.writer(f) \n",
    "#         writer.writerow(notebook_header)\n",
    "\n",
    "os.makedirs(os.path.dirname(algorithm_performance_out), exist_ok=True)\n",
    "with open(algorithm_performance_out, mode='a+', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f) \n",
    "#         writer.writerow(algorithm_header)\n",
    "\n",
    "for nb_file in notebook_list:\n",
    "    \n",
    "    result = conn.gsql('DROP ALL')\n",
    "    print ('Dropping all graphs, loading jobs, and queries sucessfully.\\n')\n",
    "    \n",
    "    print ('Executing notebook: ' + nb_file)\n",
    "    \n",
    "    root = '/home/tigergraph/GraphML/'\n",
    "    \n",
    "    nb_file = nb_file.replace(\"./\", root)\n",
    "    \n",
    "    cmd = 'cd {} && jupyter nbconvert --to html --execute {} --output-dir=/home/tigergraph/GraphML/output/{}'.format(os.path.dirname(nb_file), os.path.basename(nb_file), nb_file.replace(\"/home/tigergraph/GraphML/\", \"\"))\n",
    "    print (cmd)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    notebook_memory = %memit -r 1 -o os.system(cmd)\n",
    "    \n",
    "    notebook_memory = str(notebook_memory)\n",
    "    \n",
    "    start = notebook_memory.find(\": \") + 1\n",
    "    end = notebook_memory.find(\"M\")\n",
    "    \n",
    "    notebook_memory = notebook_memory[start:end].strip()\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    cpu_usage = psutil.cpu_percent(4)\n",
    "    \n",
    "    print('The CPU usage is: ', cpu_usage)\n",
    "    \n",
    "    # print('RAM memory % used:', psutil.virtual_memory()[2])\n",
    "    \n",
    "    host_memory = psutil.virtual_memory()[3]/1000000000\n",
    "\n",
    "    print('RAM Used (GB):', host_memory)\n",
    "    \n",
    "    print (nb_file + ' executed successfully')\n",
    "    \n",
    "    print ('execution time: ' + str(execution_time) + ' seconds\\n')\n",
    "    \n",
    "    nb_file = nb_file.replace(\"/home/tigergraph/GraphML/\", \"\")\n",
    "    \n",
    "    nb_file = nb_file.replace(\"/\", \"_\")\n",
    "    \n",
    "    nb_id = nb_file + \"_\" + config[\"job_id\"]\n",
    "    \n",
    "    job_id = \"job_\" + config[\"job_id\"]\n",
    "    \n",
    "    data = [nb_id, \"false\" ,cpu_usage, notebook_memory, execution_time, host_memory, \"no error\", job_id]\n",
    "    \n",
    "    os.makedirs(os.path.dirname(notebook_performance_out), exist_ok=True)\n",
    "    with open(notebook_performance_out, mode='a+', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f) \n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e80112-206e-46d8-9bb7-7ab5aa0d0027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2gv9fsarue5i0c2usaqpvt4qqagpubfe', 1675546065, '2023-02-04 21:27:45')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyTigerGraph import TigerGraphConnection\n",
    "\n",
    "conn = TigerGraphConnection(\n",
    "    host=config[\"monitor_host\"],\n",
    "    username=config[\"monitor_username\"],\n",
    "    password=config[\"monitor_password\"],\n",
    "    graphname=config[\"monitor_graph\"]\n",
    ")\n",
    "conn.getToken(conn.createSecret())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bcddb06-bc2c-4b6a-8d8f-5398dd85befe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sourceFileName': 'Online_POST', 'statistics': {'validLine': 20, 'rejectLine': 0, 'failedConditionLine': 0, 'notEnoughToken': 0, 'invalidJson': 0, 'oversizeToken': 0, 'vertex': [{'typeName': 'Notebook', 'validObject': 20, 'noIdFound': 0, 'invalidAttribute': 0, 'invalidVertexType': 0, 'invalidPrimaryId': 0, 'invalidSecondaryId': 0, 'incorrectFixedBinaryLength': 0}], 'edge': [{'typeName': 'hasNotebook', 'validObject': 20, 'noIdFound': 0, 'invalidAttribute': 0, 'invalidVertexType': 0, 'invalidPrimaryId': 0, 'invalidSecondaryId': 0, 'incorrectFixedBinaryLength': 0}], 'deleteVertex': [], 'deleteEdge': []}}]\n"
     ]
    }
   ],
   "source": [
    "uploadNotebookFile = conn.runLoadingJobWithFile(notebook_performance_out, \"notebook_file\", \"load_mlwb_monitor\", \",\")\n",
    "print (uploadNotebookFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03195591-4df2-4b9c-9c22-226c94f6f0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sourceFileName': 'Online_POST', 'statistics': {'validLine': 26, 'rejectLine': 0, 'failedConditionLine': 0, 'notEnoughToken': 0, 'invalidJson': 0, 'oversizeToken': 0, 'vertex': [{'typeName': 'Algorithm', 'validObject': 26, 'noIdFound': 0, 'invalidAttribute': 0, 'invalidVertexType': 0, 'invalidPrimaryId': 0, 'invalidSecondaryId': 0, 'incorrectFixedBinaryLength': 0}], 'edge': [{'typeName': 'runAlgorithm', 'validObject': 26, 'noIdFound': 0, 'invalidAttribute': 0, 'invalidVertexType': 0, 'invalidPrimaryId': 0, 'invalidSecondaryId': 0, 'incorrectFixedBinaryLength': 0}], 'deleteVertex': [], 'deleteEdge': []}}]\n"
     ]
    }
   ],
   "source": [
    "uploadAlgorithmFile = conn.runLoadingJobWithFile(algorithm_performance_out, \"algorithm_file\", \"load_mlwb_monitor\", \",\")\n",
    "print (uploadAlgorithmFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c49192e-7a32-47bf-8b1c-6c3078973187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypistats in /opt/conda/lib/python3.9/site-packages (1.2.1)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.9/site-packages (from pypistats) (2.8.2)\n",
      "Requirement already satisfied: pytablewriter[html]>=0.63 in /opt/conda/lib/python3.9/site-packages (from pypistats) (0.64.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.9/site-packages (from pypistats) (2.5.2)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.9/site-packages (from pypistats) (2.1.1)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.9/site-packages (from pypistats) (7.0.0)\n",
      "Requirement already satisfied: prettytable>=2.4 in /opt/conda/lib/python3.9/site-packages (from pypistats) (3.5.0)\n",
      "Requirement already satisfied: httpx>=0.19 in /opt/conda/lib/python3.9/site-packages (from pypistats) (0.23.2)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /opt/conda/lib/python3.9/site-packages (from httpx>=0.19->pypistats) (0.16.3)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /opt/conda/lib/python3.9/site-packages (from httpx>=0.19->pypistats) (1.5.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.9/site-packages (from httpx>=0.19->pypistats) (1.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from httpx>=0.19->pypistats) (2022.9.24)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prettytable>=2.4->pypistats) (0.2.5)\n",
      "Requirement already satisfied: pathvalidate<3,>=2.3.0 in /opt/conda/lib/python3.9/site-packages (from pytablewriter[html]>=0.63->pypistats) (2.5.2)\n",
      "Requirement already satisfied: DataProperty<2,>=0.55.0 in /opt/conda/lib/python3.9/site-packages (from pytablewriter[html]>=0.63->pypistats) (0.55.0)\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /opt/conda/lib/python3.9/site-packages (from pytablewriter[html]>=0.63->pypistats) (65.5.1)\n",
      "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from pytablewriter[html]>=0.63->pypistats) (1.1.1)\n",
      "Requirement already satisfied: tabledata<2,>=1.3.0 in /opt/conda/lib/python3.9/site-packages (from pytablewriter[html]>=0.63->pypistats) (1.3.0)\n",
      "Requirement already satisfied: typepy[datetime]<2,>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from pytablewriter[html]>=0.63->pypistats) (1.3.0)\n",
      "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /opt/conda/lib/python3.9/site-packages (from pytablewriter[html]>=0.63->pypistats) (0.1.2)\n",
      "Requirement already satisfied: dominate<3,>=2.1.5 in /opt/conda/lib/python3.9/site-packages (from pytablewriter[html]>=0.63->pypistats) (2.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil->pypistats) (1.16.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.9/site-packages (from python-slugify->pypistats) (1.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx>=0.19->pypistats) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx>=0.19->pypistats) (3.6.2)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /opt/conda/lib/python3.9/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter[html]>=0.63->pypistats) (5.1.0)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.9/site-packages (from rfc3986[idna2008]<2,>=1.3->httpx>=0.19->pypistats) (3.4)\n",
      "Requirement already satisfied: pytz>=2018.9 in /opt/conda/lib/python3.9/site-packages (from typepy[datetime]<2,>=1.2.0->pytablewriter[html]>=0.63->pypistats) (2022.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from typepy[datetime]<2,>=1.2.0->pytablewriter[html]>=0.63->pypistats) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->typepy[datetime]<2,>=1.2.0->pytablewriter[html]>=0.63->pypistats) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypistats\n",
    "import pypistats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb69ff42-2ae9-41e0-84e1-aad0aabeda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyTigergraph_statistic_out = '/home/tigergraph/GraphML/output/pytigergraph_' + config[\"job_id\"] + '.csv' \n",
    "os.makedirs(os.path.dirname(pyTigergraph_statistic_out), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "803468cc-d1de-4e58-94af-7f74443a65a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         category        date percent  downloads   pytigergraph_id  \\\n",
      "350  with_mirrors  2022-07-08   0.23%        215  pytigergraph_123   \n",
      "317  with_mirrors  2022-07-09   0.30%        281  pytigergraph_123   \n",
      "98   with_mirrors  2022-07-10   0.56%        532  pytigergraph_123   \n",
      "126  with_mirrors  2022-07-11   0.50%        472  pytigergraph_123   \n",
      "127  with_mirrors  2022-07-12   0.50%        472  pytigergraph_123   \n",
      "..            ...         ...     ...        ...               ...   \n",
      "345  with_mirrors  2022-12-31   0.24%        232  pytigergraph_123   \n",
      "187  with_mirrors  2023-01-01   0.41%        389  pytigergraph_123   \n",
      "151  with_mirrors  2023-01-02   0.46%        440  pytigergraph_123   \n",
      "226  with_mirrors  2023-01-03   0.37%        351  pytigergraph_123   \n",
      "105  with_mirrors  2023-01-04   0.54%        514  pytigergraph_123   \n",
      "\n",
      "    cron_job_id       download_id pytg_version  git_download  \n",
      "350     job_123    download_123_1        1.2.2             0  \n",
      "317     job_123    download_123_2        1.2.2             0  \n",
      "98      job_123    download_123_3        1.2.2             0  \n",
      "126     job_123    download_123_4        1.2.2             0  \n",
      "127     job_123    download_123_5        1.2.2             0  \n",
      "..          ...               ...          ...           ...  \n",
      "345     job_123  download_123_177        1.2.2             0  \n",
      "187     job_123  download_123_178        1.2.2             0  \n",
      "151     job_123  download_123_179        1.2.2             0  \n",
      "226     job_123  download_123_180        1.2.2             0  \n",
      "105     job_123  download_123_181        1.2.2             0  \n",
      "\n",
      "[181 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "pip_data = pypistats.overall(\"pyTigerGraph\", total=True, format=\"pandas\")\n",
    "pip_data = pip_data.groupby(\"category\").get_group(\"with_mirrors\").sort_values(\"date\")\n",
    "pip_data = pip_data.sort_values(\"date\")\n",
    "pip_data[\"pytigergraph_id\"] = \"pytigergraph_\" + config[\"job_id\"]\n",
    "pip_data[\"cron_job_id\"] = \"job_\" + config[\"job_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665f84f7",
   "metadata": {},
   "source": [
    "## git download of pyTigerGraph using https://docs.github.com/en/rest/metrics/traffic?apiVersion=2022-11-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede52cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl \\\n",
    "  -H \"Accept: application/vnd.github+json\" \\\n",
    "  -H @token.txt  \\\n",
    "  -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "  https://api.github.com/repos/tigergraph/pyTigerGraph/traffic/clones > pyTigerGraph.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c9109",
   "metadata": {},
   "source": [
    "## git download of graph-ml-notebook using https://docs.github.com/en/rest/metrics/traffic?apiVersion=2022-11-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl \\\n",
    "  -H \"Accept: application/vnd.github+json\" \\\n",
    "  -H @token.txt  \\\n",
    "  -H \"X-GitHub-Api-Version: 2022-11-28\" \\\n",
    "  https://api.github.com/repos/tigergraph/graph-ml-notebooks/traffic/clones > gmlNotebook.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e121a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "# load data using Python JSON module\n",
    "with open('pyTigerGraph.json','r') as f:\n",
    "    pytg_git_data = json.loads(f.read())\n",
    "# Flatten data\n",
    "pytg_git_data = pd.json_normalize(pytg_git_data, record_path =['clones'])\n",
    "\n",
    "pytg_git_data['timestamp'] = pytg_git_data['timestamp'].replace('T00:00:00Z','',regex=True)\n",
    "\n",
    "print (pytg_git_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3308e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data using Python JSON module\n",
    "with open('gmlNotebook.json','r') as f:\n",
    "    gmln_git_data = json.loads(f.read())\n",
    "# Flatten data\n",
    "gmln_git_data = pd.json_normalize(gmln_git_data, record_path =['clones'])\n",
    "\n",
    "gmln_git_data['timestamp'] = gmln_git_data['timestamp'].replace('T00:00:00Z','',regex=True)\n",
    "\n",
    "print (gmln_git_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7730eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytg_pip_data = pd.DataFrame.from_dict(pip_data)\n",
    "print (pytg_pip_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad363ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(pytg_pip_data, pytg_git_data, left_on='date', right_on='timestamp', how='left')\n",
    "\n",
    "print (merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "download_id_list = []\n",
    "for i in range(len(data.index)):\n",
    "    download_id_list.append(\"download_\" + config[\"job_id\"] + \"_\" + str(i + 1))\n",
    "    \n",
    "merged_data[\"download_id\"] = download_id_list\n",
    "merged_data[\"version\"] = \"\"\n",
    "\n",
    "merged_data['count'] = merged_data['count'].fillna(0)\n",
    "merged_data['count'] = merged_data['count'].astype(np.int64)\n",
    "merged_data.to_csv(pyTigergraph_statistic_out, index=False, header=False, columns=['date', 'downloads', 'pytigergraph_id', 'cron_job_id', 'download_id', 'version', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmlNotebook_statistic_out = '/home/tigergraph/GraphML/output/gmlnotebook_' + config['job_id'] + '.csv' \n",
    "\n",
    "download_id_list = []\n",
    "for i in range(len(gmln_git_data.index)):\n",
    "    download_id_list.append(\"gmln_download_\" + config[\"job_id\"] + \"_\" + str(i + 1))\n",
    "    \n",
    "gmln_git_data[\"download_id\"] = download_id_list\n",
    "gmln_git_data[\"version\"] = \"\"\n",
    "gmln_git_data[\"downloads\"] = 0\n",
    "gmln_git_data[\"gmlnotebook_id\"] = \"gmlnotebook_\" + config[\"job_id\"]\n",
    "gmln_git_data[\"cron_job_id\"] = \"job_\" + config[\"job_id\"]\n",
    "\n",
    "gmln_git_data['count'] = gmln_git_data['count'].fillna(0)\n",
    "gmln_git_data['count'] = gmln_git_data['count'].astype(np.int64)\n",
    "gmln_git_data['downloads'] = gmln_git_data['downloads'].astype(np.int64)\n",
    "gmln_git_data.to_csv(gmlNotebook_statistic_out, index=False, header=False, columns=['timestamp', 'downloads', 'gmlnotebook_id', 'cron_job_id', 'download_id', 'version', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c126cfe1-762f-4dee-a934-dc885043ebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sourceFileName': 'Online_POST', 'statistics': {'validLine': 181, 'rejectLine': 0, 'failedConditionLine': 0, 'notEnoughToken': 0, 'invalidJson': 0, 'oversizeToken': 0, 'vertex': [{'typeName': 'Download', 'validObject': 181, 'noIdFound': 0, 'invalidAttribute': 0, 'invalidVertexType': 0, 'invalidPrimaryId': 0, 'invalidSecondaryId': 0, 'incorrectFixedBinaryLength': 0}], 'edge': [{'typeName': 'usePyTigerGraph', 'validObject': 181, 'noIdFound': 0, 'invalidAttribute': 0, 'invalidVertexType': 0, 'invalidPrimaryId': 0, 'invalidSecondaryId': 0, 'incorrectFixedBinaryLength': 0}, {'typeName': 'hasDownload', 'validObject': 181, 'noIdFound': 0, 'invalidAttribute': 0, 'invalidVertexType': 0, 'invalidPrimaryId': 0, 'invalidSecondaryId': 0, 'incorrectFixedBinaryLength': 0}], 'deleteVertex': [], 'deleteEdge': []}}]\n"
     ]
    }
   ],
   "source": [
    "uploadPyTigerGraphFile = conn.runLoadingJobWithFile(pyTigergraph_statistic_out, \"pyTigerGraph_file\", \"load_mlwb_monitor\", \",\")\n",
    "print (uploadPyTigerGraphFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d243167e-df1f-4e3a-997d-1e3a3432af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = config['job_id']\n",
    "!curl --insecure --user graphsql:graphsql -T /home/tigergraph/GraphML/output/notebook_* sftp://192.168.99.219/home/graphsql/app-e2e/workspace/mlwb_regression_cron_trigger/monitoring_metrics/regression_$job_id/\n",
    "!curl --insecure --user graphsql:graphsql -T /home/tigergraph/GraphML/output/algorithm_* sftp://192.168.99.219/home/graphsql/app-e2e/workspace/mlwb_regression_cron_trigger/monitoring_metrics/regression_$job_id/\n",
    "!curl --insecure --user graphsql:graphsql -T /home/tigergraph/GraphML/output/pytigergraph_* sftp://192.168.99.219/home/graphsql/app-e2e/workspace/mlwb_regression_cron_trigger/monitoring_metrics/regression_$job_id/\n",
    "!curl --insecure --user graphsql:graphsql -T /home/tigergraph/GraphML/output/gmlnotebook_* sftp://192.168.99.219/home/graphsql/app-e2e/workspace/mlwb_regression_cron_trigger/monitoring_metrics/regression_$job_id/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
