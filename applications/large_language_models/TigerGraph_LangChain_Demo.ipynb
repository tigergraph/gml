{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "573df91e-c773-4f81-8344-43399b9ded00",
   "metadata": {},
   "source": [
    "# Integrate TigerGraph with LangChain with pyTigerGraph\n",
    "\n",
    "LangChain is a Python library that integrates Large Language Models (LLMs) such as OpenAI's GPT models and Google's BARD models, among others. There are many benefits to linking a natural language interface to graph databases such as TigerGraph, as models can be grounded in their generation based off of the data the database provides. This reduces the chances of these model's responses to be inaccurate, known as *hallucination*.\n",
    "\n",
    "In this demo, we are going to integrate LangChain with the Python driver of TigerGraph, pyTigerGraph. We will build up various LangChain tools in order for the LLMs to best extract the information from the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9790e156-0bfa-44cd-9434-9a735adbc0fb",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "First, we are going to install the dependencies. This consists of LangChain and OpenAI's package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36631f60-4282-4757-a8e7-63b45226790e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.9/site-packages (0.0.190)\n",
      "Requirement already satisfied: openai in /opt/conda/lib/python3.9/site-packages (0.27.7)\n",
      "Requirement already satisfied: pyTigerGraph in /opt/conda/lib/python3.9/site-packages (1.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /opt/conda/lib/python3.9/site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.9/site-packages (from langchain) (1.23.0)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/conda/lib/python3.9/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.9/site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.9/site-packages (from langchain) (2.0.15)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /opt/conda/lib/python3.9/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.9/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.9/site-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.9/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.9/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /opt/conda/lib/python3.9/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: validators in /opt/conda/lib/python3.9/site-packages (from pyTigerGraph) (0.20.0)\n",
      "Requirement already satisfied: pyTigerDriver in /opt/conda/lib/python3.9/site-packages (from pyTigerGraph) (1.0.15)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/conda/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/conda/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.9/site-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /opt/conda/lib/python3.9/site-packages (from validators->pyTigerGraph) (5.1.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0917133-b028-436a-902d-11ded876c8f5",
   "metadata": {},
   "source": [
    "## Configure Connection to OpenAI and TigerGraph Database\n",
    "\n",
    "Here, we are going to set our OpenAI API key as an environment variable for use by the LangChain library. **NOTE: You must provide your own OpenAI API key in the cell below.** Additionally, we are going to connect to our TigerGraph database, which has the OGB_MAG citation network loaded into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b84ed3f-447a-4350-b511-7a658516a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPEN_AI_API_KEY_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75794f08-da59-461d-9bbf-703f95cd0abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyTigerGraph import TigerGraphConnection\n",
    "from pyTigerGraph.datasets import Datasets\n",
    "import json\n",
    "\n",
    "# Read in DB configs\n",
    "with open('./config.json', \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "    \n",
    "conn = TigerGraphConnection(\n",
    "    host=config[\"host\"],\n",
    "    username=config[\"username\"],\n",
    "    password=config[\"password\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf53bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Datasets(\"OGB_MAG\")\n",
    "conn.ingestDataset(dataset, getToken=config[\"getToken\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "457a7e75-6dc4-4017-8284-fbc2008df77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Using graph 'OGB_MAG'\\nSuccessfully dropped queries on the graph 'OGB_MAG': [get_papers_of_author].\\nSuccessfully dropped queries on the graph 'OGB_MAG': [author_at_institutions].\\nSuccessfully dropped queries on the graph 'OGB_MAG': [tg_pagerank].\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup from previous executions of the notebook\n",
    "\n",
    "conn.gsql(\"\"\"USE GRAPH OGB_MAG\n",
    "             DROP QUERY get_papers_of_author\n",
    "             DROP QUERY author_at_institutions\n",
    "             DROP QUERY tg_pagerank\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47d02b0-0d9f-4b55-b9fe-b75629271eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FieldOfStudy': 59965,\n",
       " 'Institution': 8740,\n",
       " 'Paper': 736389,\n",
       " 'Author': 1134649}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.getVertexCount(\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db7398-1b03-4741-9b8d-38f23edc44b3",
   "metadata": {},
   "source": [
    "## Creating the LangChain Tools (Part 1)\n",
    "\n",
    "We are going to iterate through the building and testing of LangChain tools, progressively adding more functionality to the agent. First, we import the needed LangChain dependencies. Then, we are going to build three core tools: **MapQuestionToSchema**, **GenerateFunction**, and **ExecuteFunction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "575470a3-2845-446f-9f79-f042bb344f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "from langchain.tools.base import ToolException\n",
    "from langchain.chains import LLMChain\n",
    "from langchain import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "from typing import Optional, Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e832bc-e130-457a-b1cb-8709b20d7924",
   "metadata": {},
   "source": [
    "### Creating the MapQuestionToSchema Tool\n",
    "We want to map a user's question in natural language to the specific graph schema. For example, a question such as \"How many writers are there?\" should translate to \"How many Author Vertices are there?\", as there is not a schema element for \"Writers\", but there is one for \"Author\".\n",
    "\n",
    "We implement this via another call to a large language model, while passing the original question along with the schema elements retrieved from the graph connection. Specifically, we use pyTigerGraph's `getVertexTypes()` and `getEdgeTypes()` functions to gather schema information to be passed to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fda0b4d-7c56-4a7c-9476-d33b35a1207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapQuestionToSchema(BaseTool):\n",
    "    name = \"MapQuestionToSchema\"\n",
    "    description = \"Always run first to map the query to the graph's schema\"\n",
    "    conn: TigerGraphConnection = None\n",
    "    llm: LLM = None\n",
    "    handle_tool_error: bool = True\n",
    "    \n",
    "    def __init__(self, conn, llm):\n",
    "        super().__init__()\n",
    "        self.conn = conn\n",
    "        self.llm = llm\n",
    "        \n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        question_restate = \"\"\"Replace the entites mentioned in the question to one of these choices: {vertices}.\n",
    "                      Replace the relationships mentioned in the question to one of these choices: {edges}.\n",
    "                      Generate the complete question with the appropriate replacements. Keep the case of the schema elements the same.\n",
    "                      If there are no replacements to be made, restate the question.\n",
    "                      Example: How many universities are there?\n",
    "                      Response: How many vertices are University Vetexes?\n",
    "                      Example: What is the schema?\n",
    "                      Response: What is the schema?\n",
    "                      Example: How many transactions are there?\n",
    "                      Response: How many TRANSACTION Edges are there?\n",
    "                      QUESTION: {question}\n",
    "                      RESTATED: \"\"\"\n",
    "\n",
    "        RESTATE_QUESTION_PROMPT = PromptTemplate(\n",
    "            template=question_restate, input_variables=[\"question\", \"vertices\", \"edges\"]\n",
    "        )\n",
    "        \n",
    "        restate_chain = LLMChain(llm=self.llm, prompt=RESTATE_QUESTION_PROMPT)\n",
    "        \n",
    "        restate_q = restate_chain.apply([{\"vertices\": [x + \" Vertex\" for x in self.conn.getVertexTypes()], # + [x + \" Edge\" for x in conn.getEdgeTypes()],\n",
    "                                          \"question\": query,\n",
    "                                          \"edges\": [x + \" Edge\" for x in self.conn.getEdgeTypes()]}])[0][\"text\"]\n",
    "        return restate_q\n",
    "    \n",
    "    async def _arun(self) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "        \n",
    "    def _handle_error(self, error:ToolException) -> str:\n",
    "        return  \"The following errors occurred during tool execution:\" + error.args[0]+ \"Please ask for human input if they asked their question correctly.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f59118-8229-4346-90ab-097caceccc11",
   "metadata": {},
   "source": [
    "### Creating the GenerateFunctionTool\n",
    "\n",
    "We want the LLM agent to be able to generate pyTigerGraph function calls for eventual execution. We are going to once again pass the schema information, the installed queries (even though there are none installed currently), and an example of a built-in function call for pyTigerGraph such as `getVertexCount()`.\n",
    "\n",
    "This tool also utilizes pyTigerGraph to retrieve the installed queries on the graph and their parameters. This information is passed to the prompt asking the LLM to generate the appropriate function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "785d1dd0-d705-4358-a2e4-61864e022720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateFunction(BaseTool):\n",
    "    name = \"GenerateFunction\"\n",
    "    description = \"Generate a pyTigerGraph function call\"\n",
    "    conn: TigerGraphConnection = None\n",
    "    llm: LLM = None\n",
    "    handle_tool_error: bool =True\n",
    "    \n",
    "    def __init__(self, conn, llm):\n",
    "        super().__init__()\n",
    "        self.conn = conn\n",
    "        self.llm = llm\n",
    "    \n",
    "    def _run(self, question: str) -> str:\n",
    "        prompt_template = \"\"\"Use the vertex types, edge types to write the pyTigerGraph function call to answer the question using a pyTigerGraph connection.\n",
    "                            For example, if a count of vertices is asked for, use getVertexCount().\n",
    "                            If multiple entites are referred to in the question, use runInstalledQuery() when necessary.\n",
    "                            If there is not a natural answer to the question, ask a human for help.\n",
    "                            Parameters of queries to be replaced are denoted <INSERT_ID_HERE>.\n",
    "                            Vertex Types: {vertices}\n",
    "                            Edge Types: {edges}\n",
    "                            Queries: {queries}\n",
    "                            Question: {question}\n",
    "                            Python Call: conn.\"\"\"\n",
    "        \n",
    "        PROMPT = PromptTemplate(\n",
    "            template=prompt_template, input_variables=[\"question\", \"vertices\", \"queries\", \"edges\"]\n",
    "        )\n",
    "        queries = conn.getInstalledQueries()\n",
    "        [queries[x][\"parameters\"].pop(\"read_committed\") for x in queries] #remove read_committed\n",
    "        inputs = [{\"question\": question, \n",
    "                    \"vertices\": self.conn.getVertexTypes(), \n",
    "                    \"edges\": self.conn.getEdgeTypes(), \n",
    "                    \"queries\": [{queries[x][\"alternative_endpoint\"].split(\"/\")[-1]: queries[x][\"parameters\"]} for x in queries]\n",
    "                  }]\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=PROMPT)\n",
    "        generated = chain.apply(inputs)[0][\"text\"]\n",
    "        return generated\n",
    "\n",
    "    async def _arun(self) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "        \n",
    "    def _handle_error(error:ToolException) -> str:\n",
    "        return  \"The following errors occurred during tool execution:\" + error.args[0]+ \"Please ask for human input if they asked their question correctly.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce2de99-b903-494a-97d9-989ec84a8e81",
   "metadata": {},
   "source": [
    "### Creating ExecuteFunction Tool\n",
    "Once the function has been generated, the ExecuteFunction tool will utilize Python and pyTigerGraph to run the generated function against the TigerGraph database. The tool will return the JSON returned by the TigerGraph REST API endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7656cd0-9c9a-4714-a6f7-0b85b60aeada",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExecuteFunction(BaseTool):\n",
    "    name = \"ExecuteFunction\"\n",
    "    description = \"Execute a pyTigerGraph function\"\n",
    "    conn: TigerGraphConnection = None\n",
    "    handle_tool_error: bool =True\n",
    "    \n",
    "    def __init__(self, conn):\n",
    "        super().__init__()\n",
    "        self.conn = conn\n",
    "        \n",
    "    def _run(self, function: str) -> str:\n",
    "        try:\n",
    "            loc = {}\n",
    "            exec(\"res = conn.\"+function, {\"conn\": conn}, loc)\n",
    "            return loc[\"res\"]\n",
    "        except:\n",
    "            raise ToolException(\"The function {} did not execute directly. Please rephrase your question and try again\".format(function))\n",
    "    \n",
    "    async def _arun(self) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")\n",
    "        \n",
    "    def _handle_error(error:ToolException) -> str:\n",
    "        return  \"The following errors occurred during tool execution:\" + error.args[0]+ \"Please ask for human input if they asked their question correctly.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f92e579-2fc4-4000-9d49-9c867df895e8",
   "metadata": {},
   "source": [
    "## Initialize LLM and AI Agent\n",
    "\n",
    "Here, we are going to initialize our OpenAI GPT-3 LLM connection, define our tools, and create our LangChain AI Agent. The Agent is able to execute multiple tasks/tools in a linear fashion until it is satisified to answer the question. In this case, we are going to use the tools defined above to start answering questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dfd0831-080d-440f-9c81-2f1c04d09f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model_name=\"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b6014f-7cb7-42b0-8912-16a7b843cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [MapQuestionToSchema(conn, llm), GenerateFunction(conn, llm),  ExecuteFunction(conn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dc4ba37-2a71-4b8f-bdb4-4eeab6a05b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed40b00a-bd50-4fd2-b5bd-ceb95a0e378f",
   "metadata": {},
   "source": [
    "## Start Asking Questions\n",
    "We are going to start asking the agent some questions. We are going to start easy and progressively get harder, and observe when things break. After that, we will modify our tool set and add queries to the database to help the agent answer more questions. We will start with basic counts of certain schema elements, then work our way into traversals and analytic queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32544960-0c68-4dc4-8b8b-ff6429556d0b",
   "metadata": {},
   "source": [
    "### Some Easy Questions\n",
    "Here, we ask the agent some basic questions, such as \"how many papers are there?\" and \"how many citations are there?\" - notice that the agent usedc the `getEdgeCount()` function of pyTigerGraph despite never specifically being prompted to do so. This shows the LLM's inference power to transfer the prompt example of `getVertexCount()` and use it for edge counting instead. Additionally, the \"How many writers are there?\" was correctly translated to \"How many Author Vertices are there?\" to match the graph's schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1ed9b9d-fe06-4511-9142-afd4d65f115b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out how many Papers are in the graph\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: How many Papers are there?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m How many vertices are Paper Vertexes?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to count the number of Paper Vertexes\n",
      "Action: GenerateFunction\n",
      "Action Input: Count the number of Paper Vertexes\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mgetVertexCount('Paper')\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the count\n",
      "Action: ExecuteFunction\n",
      "Action Input: getVertexCount('Paper')\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m736389\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: There are 736389 Papers.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 736389 Papers.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How many Papers are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03302d64-2410-4542-9257-3f6761cab1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out how many citations are in the graph\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: How many citations are there?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m How many CITES Edges are there?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to count the number of CITES edges\n",
      "Action: GenerateFunction\n",
      "Action Input: COUNT CITES\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mgetEdgeCount('CITES')\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the number of CITES edges\n",
      "Action: ExecuteFunction\n",
      "Action Input: getEdgeCount('CITES')\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m5416271\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: There are 5416271 citations.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'There are 5416271 citations.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How many citations are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d0ee570-5c26-47f9-a744-03e23c8472ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out how many writers there are in the graph.\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: How many writers are there?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m How many vertices are Author Vertexes?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to count the number of Author vertices.\n",
      "Action: GenerateFunction\n",
      "Action Input: Count the number of Author vertices\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mgetVertexCount('Author')\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the answer.\n",
      "Action: ExecuteFunction\n",
      "Action Input: getVertexCount('Author')\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m1134649\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: 1134649 writers.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1134649 writers.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How many writers are there?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6b5d8f-da57-437d-8e94-576dc2e7a9da",
   "metadata": {},
   "source": [
    "### Some Hard Questions\n",
    "Here, we are going to ask some questions that the current prompts and queries installed on the database can't answer. We will start with a simple `getVertexCount()` but with a `where` filter, then move on to traversal and analytic queries. These questions will cause the agent to work really hard, but won't find a solution within the execution limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcc5412c-e32f-421f-ad1e-741889eabe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find all the papers with a y attribute equal to 1.\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: How many papers have a y attribute equal to 1?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m How many Paper Vertexes have a y attribute equal to 1?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to find the answer\n",
      "Action: GenerateFunction\n",
      "Action Input: Find all Paper Vertexes with a y attribute equal to 1\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('Find_Papers_with_y_attribute_equal_to_1', {'y': 1})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('Find_Papers_with_y_attribute_equal_to_1', {'y': 1})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('Find_Papers_with_y_attribute_equal_to_1', {'y': 1}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to rephrase my question\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: How many Paper Vertexes have a y attribute equal to 1?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m How many Paper Vertexes have an attribute y equal to 1?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to find the answer\n",
      "Action: GenerateFunction\n",
      "Action Input: Find all Paper Vertexes with an attribute y equal to 1\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('Find_Papers_with_Attribute_y_Equal_to_1', {'y': 1})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('Find_Papers_with_Attribute_y_Equal_to_1', {'y': 1})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('Find_Papers_with_Attribute_y_Equal_to_1', {'y': 1}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to rephrase my question\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: How many Paper Vertexes have an attribute y equal to 1?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m How many Paper Vertexes have an attribute y equal to 1?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to find the answer\n",
      "Action: GenerateFunction\n",
      "Action Input: Find all Paper Vertexes with an attribute y equal to 1\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('Find_Papers_with_Attribute_y_Equal_to_1', {'y': 1})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('Find_Papers_with_Attribute_y_Equal_to_1', {'y': 1})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('Find_Papers_with_Attribute_y_Equal_to_1', {'y': 1}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to rephrase my question\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: How many Paper Vertexes have an attribute y equal to 1?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m How many Paper Vertexes have an attribute y equal to 1?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to find the answer\n",
      "Action: GenerateFunction\n",
      "Action Input: Find all Paper Vertexes with an attribute y equal to 1\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('Find_Papers_with_Attribute_y_Equal_to_1', {'y': 1})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('Find_Papers_with_Attribute_y_Equal_to_1', {'y': 1})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('Find_Papers_with_Attribute_y_Equal_to_1', {'y': 1}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to rephrase my question\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: How many Paper Vertexes have an attribute y equal to 1?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m How many Paper Vertexes have an attribute y equal to 1?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to find the answer\n",
      "Action: GenerateFunction\n",
      "Action Input: Find all Paper Vertexes with an attribute y equal to 1\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('Find_Papers_with_Attribute_y_Equal_to_1', {'y': 1})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('Find_Papers_with_Attribute_y_Equal_to_1', {'y': 1})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('Find_Papers_with_Attribute_y_Equal_to_1', {'y': 1}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Agent stopped due to iteration limit or time limit.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How many papers have a y attribute equal to 1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5660ebb5-9877-4d65-bb64-adf4adc042c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the institutions associated with author 45\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: What institutions did author 45 work at?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m What Institutions are IS_AFFILIATED_WITH Edges connected to Author Vertex 45?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to get the institutions associated with author 45\n",
      "Action: GenerateFunction\n",
      "Action Input: Get the IS_AFFILIATED_WITH Edges connected to Author Vertex 45\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('getEdges', {'vertexType': 'Author', 'vertexId': '45', 'edgeType': 'IS_AFFILIATED_WITH'})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the institutions associated with author 45\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('getEdges', {'vertexType': 'Author', 'vertexId': '45', 'edgeType': 'IS_AFFILIATED_WITH'})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('getEdges', {'vertexType': 'Author', 'vertexId': '45', 'edgeType': 'IS_AFFILIATED_WITH'}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the institutions associated with author 45\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: What institutions is author 45 affiliated with?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m What Institutions are Vertexes connected to Author Vertex 45 via the IS_AFFILIATED_WITH Edge?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to get the institutions associated with author 45\n",
      "Action: GenerateFunction\n",
      "Action Input: Get the Vertexes connected to Author Vertex 45 via the IS_AFFILIATED_WITH Edge\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('getConnectedVertexes', {'vertex_id': '45', 'vertex_type': 'Author', 'edge_type': 'IS_AFFILIATED_WITH'})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the institutions associated with author 45\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('getConnectedVertexes', {'vertex_id': '45', 'vertex_type': 'Author', 'edge_type': 'IS_AFFILIATED_WITH'})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('getConnectedVertexes', {'vertex_id': '45', 'vertex_type': 'Author', 'edge_type': 'IS_AFFILIATED_WITH'}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the institutions associated with author 45\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: What institutions is author 45 affiliated with?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m What Institutions are Vertexes connected to Author Vertex 45 by an IS_AFFILIATED_WITH Edge?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to get the institutions associated with author 45\n",
      "Action: GenerateFunction\n",
      "Action Input: Get the Vertexes connected to Author Vertex 45 by an IS_AFFILIATED_WITH Edge\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('getConnectedVertexes', {'vertex_id': 45, 'vertex_type': 'Author', 'edge_type': 'IS_AFFILIATED_WITH'})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the institutions associated with author 45\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('getConnectedVertexes', {'vertex_id': 45, 'vertex_type': 'Author', 'edge_type': 'IS_AFFILIATED_WITH'})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('getConnectedVertexes', {'vertex_id': 45, 'vertex_type': 'Author', 'edge_type': 'IS_AFFILIATED_WITH'}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the institutions associated with author 45\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: What institutions is author 45 affiliated with?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m What Institutions are Vertexes connected to Author Vertex 45 via the IS_AFFILIATED_WITH Edge?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to get the institutions associated with author 45\n",
      "Action: GenerateFunction\n",
      "Action Input: Get the Vertexes connected to Author Vertex 45 via the IS_AFFILIATED_WITH Edge\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('getConnectedVertexes', {'vertex_id': 45, 'vertex_type': 'Author', 'edge_type': 'IS_AFFILIATED_WITH'})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the institutions associated with author 45\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('getConnectedVertexes', {'vertex_id': 45, 'vertex_type': 'Author', 'edge_type': 'IS_AFFILIATED_WITH'})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('getConnectedVertexes', {'vertex_id': 45, 'vertex_type': 'Author', 'edge_type': 'IS_AFFILIATED_WITH'}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the institutions associated with author 45\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: What institutions is author 45 affiliated with?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m What Institutions are Vertexes connected to Author Vertex 45 via the IS_AFFILIATED_WITH Edge?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to get the institutions associated with author 45\n",
      "Action: GenerateFunction\n",
      "Action Input: Get the Vertexes connected to Author Vertex 45 via the IS_AFFILIATED_WITH Edge\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('getConnectedVertexes', {'vertex_id': '45', 'vertex_type': 'Author', 'edge_type': 'IS_AFFILIATED_WITH'})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the institutions associated with author 45\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('getConnectedVertexes', {'vertex_id': '45', 'vertex_type': 'Author', 'edge_type': 'IS_AFFILIATED_WITH'})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('getConnectedVertexes', {'vertex_id': '45', 'vertex_type': 'Author', 'edge_type': 'IS_AFFILIATED_WITH'}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Agent stopped due to iteration limit or time limit.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What institutions did author 45 work at?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14c2402d-1e35-499e-95fe-fbe626108ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the papers with the most citations\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: By citations, what are the 10 most influential papers?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m By CITES Edges, what are the 10 most influential Paper Vertices?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to get the most influential papers\n",
      "Action: GenerateFunction\n",
      "Action Input: By CITES Edges, what are the 10 most influential Paper Vertices?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('MostInfluentialPapers', {'topK': 10})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the most influential papers\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('MostInfluentialPapers', {'topK': 10})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('MostInfluentialPapers', {'topK': 10}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the papers with the most citations\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: By citations, what are the 10 most cited papers?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m By CITES Edges, what are the 10 most cited Paper Vertices?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to get the most cited papers\n",
      "Action: GenerateFunction\n",
      "Action Input: By CITES Edges, what are the 10 most cited Paper Vertices?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('most_cited_papers', {'top_k': 10})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the most cited papers\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('most_cited_papers', {'top_k': 10})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('most_cited_papers', {'top_k': 10}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the papers with the most citations\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: What are the 10 most cited papers?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m What are the 10 most CITED Edges?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to get the most cited papers\n",
      "Action: GenerateFunction\n",
      "Action Input: What are the 10 most CITED Edges?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('MostCitedEdges', {'topK': 10})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the most cited papers\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('MostCitedEdges', {'topK': 10})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('MostCitedEdges', {'topK': 10}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the papers with the most citations\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: What are the 10 most cited papers?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m What are the 10 most CITED Edges?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to get the most cited papers\n",
      "Action: GenerateFunction\n",
      "Action Input: What are the 10 most CITED Edges?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('MostCitedEdges', {'topK': 10})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the most cited papers\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('MostCitedEdges', {'topK': 10})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('MostCitedEdges', {'topK': 10}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the papers with the most citations\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: What are the 10 most cited papers?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m What are the 10 most CITED Edges?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to get the most cited papers\n",
      "Action: GenerateFunction\n",
      "Action Input: What are the 10 most CITED Edges?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('MostCitedEdges', {'topK': 10})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the most cited papers\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('MostCitedEdges', {'topK': 10})\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe function runInstalledQuery('MostCitedEdges', {'topK': 10}) did not execute directly. Please rephrase your question and try again\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Agent stopped due to iteration limit or time limit.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"By citations, what are the 10 most influential papers?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa52e60-9fdc-45dc-b3d2-a94299923914",
   "metadata": {},
   "source": [
    "## Add Some Queries to Better Answer Questions\n",
    "\n",
    "Here we are going to add some queries to the graph to better answer some \"domain specific\" questions. These queries are quite simple, but provide a template of what more complex queries could take the form of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4f9ece8-078f-4ca7-bdd7-b93b9ab0af93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Using graph \\'OGB_MAG\\'\\nWarning in a transformed block of query author_at_institutions (WARN-2): line 6, col 31\\nunsatisfiable pattern _\\nSuccessfully created queries: [author_at_institutions].\\nStart installing queries, about 1 minute ...\\nauthor_at_institutions query: curl -X GET \\'https://127.0.0.1:9000/query/OGB_MAG/author_at_institutions?auth_id=VALUE\\'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\\nSelect \\'m1\\' as compile server, now connecting ...\\nNode \\'m1\\' is prepared as compile server.\\n\\nQuery installation finished.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.gsql(\"\"\"USE GRAPH OGB_MAG\n",
    "            CREATE OR REPLACE QUERY author_at_institutions(VERTEX<Author> auth_id) FOR GRAPH OGB_MAG { \n",
    "              start = {auth_id};\n",
    "\n",
    "              res = SELECT i FROM start:s -()- Institution:i;\n",
    "              PRINT res[res.id];\n",
    "            }\n",
    "            INSTALL QUERY author_at_institutions\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71fa7fbd-6692-4be4-983e-1d2b62f46460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Using graph \\'OGB_MAG\\'\\nWarning in a transformed block of query get_papers_of_author (WARN-2): line 5, col 31\\nunsatisfiable pattern _\\nSuccessfully created queries: [get_papers_of_author].\\nStart installing queries, about 1 minute ...\\nget_papers_of_author query: curl -X GET \\'https://127.0.0.1:9000/query/OGB_MAG/get_papers_of_author?auth=VALUE\\'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\\nSelect \\'m1\\' as compile server, now connecting ...\\nNode \\'m1\\' is prepared as compile server.\\n\\nQuery installation finished.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.gsql(\"\"\"USE GRAPH OGB_MAG\n",
    "            CREATE OR REPLACE QUERY get_papers_of_author(VERTEX<Author> auth) FOR GRAPH OGB_MAG { \n",
    "              start = {auth};\n",
    "              res = SELECT p FROM start:s -()- Paper:p;\n",
    "              PRINT res[res.id];\n",
    "            }\n",
    "            INSTALL QUERY get_papers_of_author\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9836eaec-b896-489f-b5fd-974ee6d4547e",
   "metadata": {},
   "source": [
    "### Test the Queries with the Agent\n",
    "Since the **GenerateFunction** tool automatically pulls the queries available to it at execution time, we can immediately test if our new queries are used by the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8970c43-7561-4aae-bf22-2e2e7d2db590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the institutions associated with author 45\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: What institutions did author 45 work at?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m What Institutions are IS_AFFILIATED_WITH Edges connected to Author Vertex 45?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to get the institutions associated with author 45\n",
      "Action: GenerateFunction\n",
      "Action Input: Get the IS_AFFILIATED_WITH Edges connected to Author Vertex 45\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('author_at_institutions', {'auth_id': 45})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the institutions associated with author 45\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('author_at_institutions', {'auth_id': 45})\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m[{'res': [{'v_id': '649', 'v_type': 'Institution', 'attributes': {'res.id': 649}}]}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The institution with id 649 is the institution that author 45 is affiliated with.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The institution with id 649 is the institution that author 45 is affiliated with.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What institutions did author 45 work at?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c27a7585-4c63-41b4-8f17-cd85b22a9954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the papers written by author 5\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: What papers did author 5 write?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m What WROTE Edges are there from Author Vertex 5?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to get the papers written by author 5\n",
      "Action: GenerateFunction\n",
      "Action Input: Get WROTE Edges from Author Vertex 5\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('get_papers_of_author', {'auth': '5'})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the papers written by author 5\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('get_papers_of_author', {'auth': '5'})\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m[{'res': [{'v_id': '539403', 'v_type': 'Paper', 'attributes': {'res.id': 539403}}, {'v_id': '676656', 'v_type': 'Paper', 'attributes': {'res.id': 676656}}, {'v_id': '215835', 'v_type': 'Paper', 'attributes': {'res.id': 215835}}]}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The papers written by author 5 are 539403, 676656, and 215835.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The papers written by author 5 are 539403, 676656, and 215835.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What papers did author 5 write?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88370716-444f-403c-ad9a-e629187628a2",
   "metadata": {},
   "source": [
    "## Add Graph Data Science Capabilities\n",
    "\n",
    "One of the questions that the agent failed to answer was \"What is the most influential paper based on citations?\". This is a question that the *PageRank algorithm* can answer. Here, we are going to install the TigerGraph implementation of PageRank to make it available to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ddd107d-3099-4f6e-8549-1a41ff9e775a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing the queries, it might take a minute...\n",
      "Queries installed successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tg_pagerank'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = conn.gds.featurizer()\n",
    "\n",
    "f.installAlgorithm(\"tg_pagerank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8755d37-1eb9-4941-ac2f-b14ab5f7c24b",
   "metadata": {},
   "source": [
    "### Test the Question\n",
    "Here, the agent maps the question of \"influence\" to the available PageRank algorithm, and correctly fills in the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0663d4ee-21ef-4c2e-8ddd-668ea06bf840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the papers with the most citations\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: By citations, what are the 10 most influential papers?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m By CITES Edges, what are the 10 most influential Paper Vertices?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to get the most influential papers\n",
      "Action: GenerateFunction\n",
      "Action Input: By CITES Edges, what are the 10 most influential Paper Vertices?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mrunInstalledQuery('tg_pagerank', {'v_type': 'Paper', 'e_type': 'CITES', 'top_k': 10})\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the most influential papers\n",
      "Action: ExecuteFunction\n",
      "Action Input: runInstalledQuery('tg_pagerank', {'v_type': 'Paper', 'e_type': 'CITES', 'top_k': 10})\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m[{'@@top_scores_heap': [{'Vertex_ID': '428523', 'score': 392.87326}, {'Vertex_ID': '384889', 'score': 251.80214}, {'Vertex_ID': '377502', 'score': 149.10182}, {'Vertex_ID': '61855', 'score': 129.7406}, {'Vertex_ID': '416200', 'score': 129.22864}, {'Vertex_ID': '380836', 'score': 125.35667}, {'Vertex_ID': '40415', 'score': 122.92435}, {'Vertex_ID': '437914', 'score': 117.94849}, {'Vertex_ID': '394406', 'score': 110.56911}, {'Vertex_ID': '533629', 'score': 103.74941}]}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The 10 most influential papers, by citations, are 428523, 384889, 377502, 61855, 416200, 380836, 40415, 437914, 394406, and 533629.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The 10 most influential papers, by citations, are 428523, 384889, 377502, 61855, 416200, 380836, 40415, 437914, 394406, and 533629.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"By citations, what are the 10 most influential papers?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce6d1a-4559-4375-b34e-370029ede329",
   "metadata": {},
   "source": [
    "## Create Specific Tools\n",
    "There is one more question that originally failed that we have not yet resolved - the question of \"How many Papers have a y attribute equal to 1?\". To do this, we could write a GSQL query. However, the pyTigerGraph `getVertexCount()` function has a `where` parameter that can be used to accomplish the same task. Unfortunately, the agent doesn't know this due to the lack of specific knowledge about pyTigerGraph. To resolve this, we can define a custom tool for getting the vertex count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0a97c15-1399-4bd5-a2fe-42642b8cb907",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateVertexCountFunction(BaseTool):\n",
    "    name = \"GenerateVertexCountFunction\"\n",
    "    description = \"Generate a pyTigerGraph function call to count vertices with filters.\"\n",
    "    conn: TigerGraphConnection = None\n",
    "    llm: LLM = None\n",
    "    handle_tool_error: bool =True\n",
    "    \n",
    "    def __init__(self, conn, llm):\n",
    "        super().__init__()\n",
    "        self.conn = conn\n",
    "        self.llm = llm\n",
    "    \n",
    "    def _run(self, question: str) -> str:\n",
    "        prompt_template = \"\"\"Use the vertex types and any potential filters to generate the conn.getVertexCount() function call.\n",
    "                          \"\"\"+self.conn.getVertexCount.__doc__.replace(\"{\", \"\").replace(\"}\", \"\")+\"\"\"\n",
    "                            Vertex Types: {vertices}\n",
    "                            Question: {question}\n",
    "                            Python Call to run the function: conn.\"\"\"\n",
    "        \n",
    "        \n",
    "        PROMPT = PromptTemplate(\n",
    "            template=prompt_template, input_variables=[\"question\", \"vertices\"]\n",
    "        )\n",
    "        queries = conn.getInstalledQueries()\n",
    "        inputs = [{\"question\": question, \n",
    "                    \"vertices\": self.conn.getVertexTypes()\n",
    "                  }]\n",
    "        \n",
    "        chain = LLMChain(llm=self.llm, prompt=PROMPT)\n",
    "        generated = chain.apply(inputs)[0][\"text\"]\n",
    "        return \"Use in ExecuteFunction tool: \"+generated\n",
    "    \n",
    "    async def _arun(self) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d84e29e5-ce30-4315-a7f3-63527a404fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [MapQuestionToSchema(conn, llm), GenerateFunction(conn, llm), GenerateVertexCountFunction(conn, llm), ExecuteFunction(conn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1d2d9a9-ccc0-4df2-ab8f-7bfb0a33f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b60c764b-a34b-4500-895c-d493998390f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to count the number of papers with a y attribute equal to 1.\n",
      "Action: MapQuestionToSchema\n",
      "Action Input: How many papers have a y attribute equal to 1?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m How many Paper Vertexes have a y attribute equal to 1?\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to generate a function to count the number of papers with a y attribute equal to 1.\n",
      "Action: GenerateVertexCountFunction\n",
      "Action Input: Paper Vertex, y attribute equal to 1\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mUse in ExecuteFunction tool: getVertexCount('Paper', where='y=1')\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to execute the function to get the answer.\n",
      "Action: ExecuteFunction\n",
      "Action Input: getVertexCount('Paper', where='y=1')\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m30902\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: 30902 papers have a y attribute equal to 1.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'30902 papers have a y attribute equal to 1.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How many papers have a y attribute equal to 1?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1d2af-1176-472e-b93e-b79d6da4e98e",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Integrating TigerGraph with LangChain using pyTigerGraph opens up exciting possibilities for enhancing natural language interfaces for graph databases. By combining the power of LLMs with the flexibility of graph databases, users can interact with the data using everyday language, reducing the learning curve and enabling more intuitive data exploration. With the LangChain AI Agent, users can ask questions, receive meaningful responses, and gain insights from the graph database in a seamless and user-friendly manner. These agents can be used by business analysts for internal uses, or can serve as the foundation for chatbots to serve results to customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf6703f-dfe5-409b-9d31-301c2114f832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
