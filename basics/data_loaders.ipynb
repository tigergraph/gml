{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a41fec-c7f0-4752-b57a-efb428327343",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d51c63-ed05-43d4-9e02-7d13763b5011",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of **data loaders** in `pyTigerGraph`. The job of a data loader is to pull data from the TigerGraph database to the machine that runs the data loaders. Currently, the following data loaders are provided:\n",
    "* EdgeLoader, which returns batches of edges.\n",
    "* VertexLoader, which returns batches of vertices.\n",
    "* GraphLoader, which returns randomly sampled (probably disconnected) subgraphs in pandas `dataframe`, `PyG` or `DGL` format.\n",
    "* NeighborLoader, which returns subgraphs as sampled in [GraphSAGE](https://arxiv.org/abs/1706.02216) in `dataframe`, `PyG` or `DGL` format.\n",
    "* EdgeNeighborLoader, which returns subgraphs using neighbor sampling from edges in `dataframe`, `PyG` or `DGL` format.\n",
    "* HGTLoader, which works similarly as NeighborLoader but performs stratified neighbor sampling as in [Heterogeneous Graph Transformer](https://arxiv.org/abs/2003.01332).\n",
    "\n",
    "Every data loader above can either get all the batches as a HTTP response (default) or stream every batch through Kafka. The former mechanism is good for testing with small graphs and it is fast, but it subjects to a data size limit of 2GB. For large graphs, the HTTP channel will likely fail due to size limit and network connectivity issues. Streaming via Kafka is offered for data robustness and scalability. Also, Kafka excels at multi-consumer use cases, and is required by distributed loader groups. \n",
    "\n",
    "The data loaders support both homogeneous and heterogenous graphs. By default, they load from all vertex and edge types and treat the graph as a homogeneous graph. But they also allow users to specify what vertex and edge types to load from and what attributes to load from each type. This way users will get heterogeneous graph outputs.\n",
    "\n",
    "**NOTE**: Currently, your database needs to be activated (only once) to work with the data loaders. If you are using the ML Workbench on tgCloud, then the bundled database is activated. Otherwise, you can download the activator at https://act.tigergraphlabs.com. Detailed instructions are also included on that website. \n",
    "\n",
    "Below we will use `NeighborLoader` for illustration. The other data loaders work similarly but use slightly different parameters. Please refer to the [reference doc](https://docs.tigergraph.com/pytigergraph/current/gds/gds) on details for each data loader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e8dc12-390c-4830-8bbb-3e8e80763867",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Connection to Database](#connection) \n",
    "* [Neighbor Loader](#neighborloader)\n",
    "  * [Homogeneous Graph](#homogeneous)\n",
    "  * [Heterogeneous Graph](#heterogeneous)\n",
    "* [Streaming through Kafka](#kafka)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff08e15-5d93-4f30-8a9d-6b101b1604e4",
   "metadata": {},
   "source": [
    "## Connection to Database <a name=\"connection\"></a>\n",
    "\n",
    "The `TigerGraphConnection` class represents a connection to the TigerGraph database. Under the hood, it stores the necessary information to communicate with the database. It is able to perform quite a few database tasks. Please see its [documentation](https://docs.tigergraph.com/pytigergraph/current/intro/) for details.\n",
    "\n",
    "To connect your database, modify the `config.json` file accompanying this notebook. Set the value of `getToken` based on whether token auth is enabled for your database. Token auth is always enabled for tgcloud databases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c4b1e8-a0e2-4026-9bb1-218cdc7ca4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyTigerGraph import TigerGraphConnection\n",
    "import json\n",
    "\n",
    "# Read in DB configs\n",
    "with open('../config.json', \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "    \n",
    "conn = TigerGraphConnection(\n",
    "    host=config[\"host\"],\n",
    "    username=config[\"username\"],\n",
    "    password=config[\"password\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d0deb8-9029-494c-8175-7675fddc862a",
   "metadata": {},
   "source": [
    "### Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7d1033-06ab-4392-8baf-df27046c57af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder with name Cora already exists in ./tmp. Skip downloading.\n"
     ]
    }
   ],
   "source": [
    "from pyTigerGraph.datasets import Datasets\n",
    "\n",
    "dataset = Datasets(\"Cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc82ea1-33f5-4605-a303-a108a64265cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Checking database ----\n",
      "A graph with name Cora already exists in the database. Skip ingestion.\n",
      "Graph name is set to Cora for this connection.\n"
     ]
    }
   ],
   "source": [
    "conn.ingestDataset(dataset, getToken=config[\"getToken\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd1ef7-fc77-4ff3-931f-ebc05aa7f2b5",
   "metadata": {},
   "source": [
    "### Visualize Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b5073a-79fc-4156-8ebd-e20c1a2df8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6960c3d17a047379cebebf0cef81617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'circle', 'animate': True, 'padding': 1}, cytoscape_style=[{'selectoâ€¦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyTigerGraph.visualization import drawSchema\n",
    "\n",
    "drawSchema(conn.getSchema(force=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb10dad-592d-4ec1-b57e-7cd61ea34637",
   "metadata": {},
   "source": [
    "### Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1dd0252-a5e5-47ee-acce-b843571c78cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Paper': 2708}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of vertices for every vertex type\n",
    "conn.getVertexCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "318f1998-1179-4ae2-9f1b-d1b032076c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cite': 10556}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of edges for every type\n",
    "conn.getEdgeCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f29ef-6b65-4999-9363-f9dfde5e478c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Neighbor Loader <a name=\"neighborloader\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19aefc0-6c7c-4815-b3c7-2a2a3fd3cd3f",
   "metadata": {},
   "source": [
    "### Homogeneous Graph <a name=\"homogeneous\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49331e44-2bd6-4e9b-b061-3de410eb4dad",
   "metadata": {},
   "source": [
    "`NeighborLoader` performs neighbor sampling as introduced in [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216) and returns neighborhood subgraphs. Hence, the subgraphs from this loader are connected. \n",
    "\n",
    "Specifically, the loader first chooses `batch_size` number of vertices as seeds, then picks `num_neighbors` number of neighbors of each seed at random, then `num_neighbors` neighbors of each neighbor, and repeat for `num_hops`. This generates one subgraph. As you loop through this data loader, every vertex will at some point be chosen as a seed and you will get the subgraph expanded from the seed. If you want to limit seeds to certain vertices, the boolean attribute provided to `filter_by` will be used to indicate which vertices can be included as seeds. \n",
    "\n",
    "The loader can be created by calling the `.gds.neighborLoader()` function on the DB connection object. Key parameters to the data loader are\n",
    "* batch_size, num_neighbors, num_hops: they are for the neighbor sampling process as described above.\n",
    "* v_in_feats, v_out_labels, v_extra_feats: those dictate which vertex attributes will be pulled from the database. They can be omitted if no vertex attribute is needed.\n",
    "* e_in_feats, e_out_labels, e_extra_feats: similar as above but for edge attributes.\n",
    "* output_format: format of the output graph. \"PyG\", \"DGL\", \"spektral\", and \"dataframe\" are supported.\n",
    "* shuffle: whether to shuffle the vertices before loading data.\n",
    "* filter_by: a boolean attribute indicating which vertices can be included as seeds.\n",
    "\n",
    "For details on those parameters and the complete parameter list, please refer to the [doc](https://docs.tigergraph.com/pytigergraph/current/gds/gds#_neighborloader).\n",
    "\n",
    "**Note**: For the first time you initialize the loader on a graph in TigerGraph,\n",
    "the initialization might take a minute as it installs the corresponding\n",
    "query to the database and optimizes it. However, the query installation only\n",
    "needs to be done once, so it will take no time when you initialize the loader\n",
    "on the same graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "269bf653-ea3a-4646-aa0d-ef539838a7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 s, sys: 154 ms, total: 1.97 s\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neighbor_loader = conn.gds.neighborLoader(\n",
    "    batch_size=16,\n",
    "    num_neighbors = 10,\n",
    "    num_hops =2,\n",
    "    v_in_feats = [\"x\"],\n",
    "    v_out_labels = [\"y\"],\n",
    "    v_extra_feats = [\"train_mask\", \"val_mask\", \"test_mask\"],\n",
    "    e_in_feats=[\"time\"],\n",
    "    e_out_labels=[],\n",
    "    e_extra_feats=[\"is_train\", \"is_val\"],\n",
    "    output_format = \"PyG\",\n",
    "    shuffle=True,\n",
    "    filter_by=\"train_mask\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0166555-7d60-4648-bf34-37819ed04f8a",
   "metadata": {},
   "source": [
    "There are two ways to use this data loader. We will try the first one below as it is more common.\n",
    "* First, it can be used as an iterable, which means you can loop through\n",
    "  it to get every batch of data. If you load all data in one batch (`num_batches=1`),\n",
    "  there will be only one batch (of all the data) in the iterator.\n",
    "* Second, you can access the `data` property of the class directly. If there is\n",
    "  only one batch of data to load, it will give you the batch directly instead\n",
    "  of an iterator, which might make more sense in that case. If there are\n",
    "  multiple batches of data to load, it will return the loader itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc82350c-9e80-4ff1-8c1b-67ae60a75a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "Data(edge_index=[2, 407], edge_feat=[407], is_train=[407], is_val=[407], x=[271, 1433], y=[271], train_mask=[271], val_mask=[271], test_mask=[271], is_seed=[271])\n",
      "----Batch 1----\n",
      "Data(edge_index=[2, 362], edge_feat=[362], is_train=[362], is_val=[362], x=[222, 1433], y=[222], train_mask=[222], val_mask=[222], test_mask=[222], is_seed=[222])\n",
      "----Batch 2----\n",
      "Data(edge_index=[2, 316], edge_feat=[316], is_train=[316], is_val=[316], x=[220, 1433], y=[220], train_mask=[220], val_mask=[220], test_mask=[220], is_seed=[220])\n",
      "----Batch 3----\n",
      "Data(edge_index=[2, 395], edge_feat=[395], is_train=[395], is_val=[395], x=[257, 1433], y=[257], train_mask=[257], val_mask=[257], test_mask=[257], is_seed=[257])\n",
      "----Batch 4----\n",
      "Data(edge_index=[2, 445], edge_feat=[445], is_train=[445], is_val=[445], x=[282, 1433], y=[282], train_mask=[282], val_mask=[282], test_mask=[282], is_seed=[282])\n",
      "----Batch 5----\n",
      "Data(edge_index=[2, 381], edge_feat=[381], is_train=[381], is_val=[381], x=[254, 1433], y=[254], train_mask=[254], val_mask=[254], test_mask=[254], is_seed=[254])\n",
      "----Batch 6----\n",
      "Data(edge_index=[2, 359], edge_feat=[359], is_train=[359], is_val=[359], x=[254, 1433], y=[254], train_mask=[254], val_mask=[254], test_mask=[254], is_seed=[254])\n",
      "----Batch 7----\n",
      "Data(edge_index=[2, 391], edge_feat=[391], is_train=[391], is_val=[391], x=[247, 1433], y=[247], train_mask=[247], val_mask=[247], test_mask=[247], is_seed=[247])\n",
      "----Batch 8----\n",
      "Data(edge_index=[2, 392], edge_feat=[392], is_train=[392], is_val=[392], x=[261, 1433], y=[261], train_mask=[261], val_mask=[261], test_mask=[261], is_seed=[261])\n",
      "CPU times: user 1.24 s, sys: 56.9 ms, total: 1.3 s\n",
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(neighbor_loader):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff561ba1",
   "metadata": {},
   "source": [
    "### Heterogeneous Graph <a name=\"heterogeneous\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dee177",
   "metadata": {},
   "source": [
    "If the code above were run on heterogeneous graphs, it would also work but would ignore vertex or edge types and output homogeneous subgraphs (it also requires that the desired attributes exist on all vertices/edges or an error will be thrown). If you need the output to be heterogeneous subgraphs, use the dict input for v_in_feats, v_out_labels, v_extra_feats, e_in_feats, e_out_labels, or e_extra_feats. Keys of the dict are vertex/edge types to be selected, and values are lists of attributes to be selected for the vertex/edge types. This also gives you fine control over what types of vertices/edges to be included in the sampling process and in the output. \n",
    "\n",
    "Although `Cora` is a homogeneous graph, we will use it to illustrate how to specify the input to get output as heterogeneous subgraphs. It is straightforward to replace this Cora graph with your heterogeneous graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29498931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute or two.\n",
      "Query installation finished.\n",
      "CPU times: user 55.8 ms, sys: 4.95 ms, total: 60.7 ms\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neighbor_loader = conn.gds.neighborLoader(\n",
    "    batch_size=16,\n",
    "    num_neighbors = 10,\n",
    "    num_hops =2,\n",
    "    v_in_feats = {\"Paper\": [\"x\"]},\n",
    "    v_out_labels = {\"Paper\": [\"y\"]},\n",
    "    v_extra_feats = {\"Paper\": [\"train_mask\", \"val_mask\", \"test_mask\"]},\n",
    "    e_in_feats={\"Cite\": [\"time\"]},\n",
    "    e_extra_feats={\"Cite\": [\"is_train\", \"is_val\"]},\n",
    "    output_format = \"PyG\",\n",
    "    shuffle=True,\n",
    "    filter_by={\"Paper\": \"train_mask\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8044336-ba1f-425c-895a-dbf7facfd945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "HeteroData(\n",
      "  \u001b[1mPaper\u001b[0m={\n",
      "    x=[278, 1433],\n",
      "    y=[278],\n",
      "    train_mask=[278],\n",
      "    val_mask=[278],\n",
      "    test_mask=[278],\n",
      "    is_seed=[278]\n",
      "  },\n",
      "  \u001b[1m(Paper, Cite, Paper)\u001b[0m={\n",
      "    edge_index=[2, 410],\n",
      "    edge_feat=[410],\n",
      "    is_train=[410],\n",
      "    is_val=[410]\n",
      "  }\n",
      ")\n",
      "----Batch 1----\n",
      "HeteroData(\n",
      "  \u001b[1mPaper\u001b[0m={\n",
      "    x=[267, 1433],\n",
      "    y=[267],\n",
      "    train_mask=[267],\n",
      "    val_mask=[267],\n",
      "    test_mask=[267],\n",
      "    is_seed=[267]\n",
      "  },\n",
      "  \u001b[1m(Paper, Cite, Paper)\u001b[0m={\n",
      "    edge_index=[2, 451],\n",
      "    edge_feat=[451],\n",
      "    is_train=[451],\n",
      "    is_val=[451]\n",
      "  }\n",
      ")\n",
      "----Batch 2----\n",
      "HeteroData(\n",
      "  \u001b[1mPaper\u001b[0m={\n",
      "    x=[252, 1433],\n",
      "    y=[252],\n",
      "    train_mask=[252],\n",
      "    val_mask=[252],\n",
      "    test_mask=[252],\n",
      "    is_seed=[252]\n",
      "  },\n",
      "  \u001b[1m(Paper, Cite, Paper)\u001b[0m={\n",
      "    edge_index=[2, 382],\n",
      "    edge_feat=[382],\n",
      "    is_train=[382],\n",
      "    is_val=[382]\n",
      "  }\n",
      ")\n",
      "----Batch 3----\n",
      "HeteroData(\n",
      "  \u001b[1mPaper\u001b[0m={\n",
      "    x=[249, 1433],\n",
      "    y=[249],\n",
      "    train_mask=[249],\n",
      "    val_mask=[249],\n",
      "    test_mask=[249],\n",
      "    is_seed=[249]\n",
      "  },\n",
      "  \u001b[1m(Paper, Cite, Paper)\u001b[0m={\n",
      "    edge_index=[2, 422],\n",
      "    edge_feat=[422],\n",
      "    is_train=[422],\n",
      "    is_val=[422]\n",
      "  }\n",
      ")\n",
      "----Batch 4----\n",
      "HeteroData(\n",
      "  \u001b[1mPaper\u001b[0m={\n",
      "    x=[238, 1433],\n",
      "    y=[238],\n",
      "    train_mask=[238],\n",
      "    val_mask=[238],\n",
      "    test_mask=[238],\n",
      "    is_seed=[238]\n",
      "  },\n",
      "  \u001b[1m(Paper, Cite, Paper)\u001b[0m={\n",
      "    edge_index=[2, 369],\n",
      "    edge_feat=[369],\n",
      "    is_train=[369],\n",
      "    is_val=[369]\n",
      "  }\n",
      ")\n",
      "----Batch 5----\n",
      "HeteroData(\n",
      "  \u001b[1mPaper\u001b[0m={\n",
      "    x=[276, 1433],\n",
      "    y=[276],\n",
      "    train_mask=[276],\n",
      "    val_mask=[276],\n",
      "    test_mask=[276],\n",
      "    is_seed=[276]\n",
      "  },\n",
      "  \u001b[1m(Paper, Cite, Paper)\u001b[0m={\n",
      "    edge_index=[2, 417],\n",
      "    edge_feat=[417],\n",
      "    is_train=[417],\n",
      "    is_val=[417]\n",
      "  }\n",
      ")\n",
      "----Batch 6----\n",
      "HeteroData(\n",
      "  \u001b[1mPaper\u001b[0m={\n",
      "    x=[179, 1433],\n",
      "    y=[179],\n",
      "    train_mask=[179],\n",
      "    val_mask=[179],\n",
      "    test_mask=[179],\n",
      "    is_seed=[179]\n",
      "  },\n",
      "  \u001b[1m(Paper, Cite, Paper)\u001b[0m={\n",
      "    edge_index=[2, 249],\n",
      "    edge_feat=[249],\n",
      "    is_train=[249],\n",
      "    is_val=[249]\n",
      "  }\n",
      ")\n",
      "----Batch 7----\n",
      "HeteroData(\n",
      "  \u001b[1mPaper\u001b[0m={\n",
      "    x=[249, 1433],\n",
      "    y=[249],\n",
      "    train_mask=[249],\n",
      "    val_mask=[249],\n",
      "    test_mask=[249],\n",
      "    is_seed=[249]\n",
      "  },\n",
      "  \u001b[1m(Paper, Cite, Paper)\u001b[0m={\n",
      "    edge_index=[2, 360],\n",
      "    edge_feat=[360],\n",
      "    is_train=[360],\n",
      "    is_val=[360]\n",
      "  }\n",
      ")\n",
      "----Batch 8----\n",
      "HeteroData(\n",
      "  \u001b[1mPaper\u001b[0m={\n",
      "    x=[216, 1433],\n",
      "    y=[216],\n",
      "    train_mask=[216],\n",
      "    val_mask=[216],\n",
      "    test_mask=[216],\n",
      "    is_seed=[216]\n",
      "  },\n",
      "  \u001b[1m(Paper, Cite, Paper)\u001b[0m={\n",
      "    edge_index=[2, 323],\n",
      "    edge_feat=[323],\n",
      "    is_train=[323],\n",
      "    is_val=[323]\n",
      "  }\n",
      ")\n",
      "CPU times: user 1.27 s, sys: 1.9 ms, total: 1.27 s\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(neighbor_loader):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8dd1f1-9139-4f7a-b10f-3ecd60226541",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Streaming through Kafka <a name=\"kafka\"></a>\n",
    "\n",
    "**Note**: Kafka streaming function is only available when the database is activated with the [Enterprise edition](https://docs.tigergraph.com/ml-workbench/current/editions/).\n",
    "\n",
    "To stream data from your DB through Kafka to the machine that runs the data loader, the only extra step is to provide the required information about your Kafka cluster and everything else works as above. \n",
    "\n",
    "Note that TigerGraph doesn't provide the Kafka cluster but only use it as a channel to stream data. You can use most Kafka clusters of your choice. Each batch (subgraph) will be a message, and hence if you need relatively large batches and your Kafka cluster has replicas, the `replica.fetch.max.bytes` setting on the Kafka cluster has to be large enough to accommadate the batches. Also, if you create a topic manually for the data loader to use, the `max.message.bytes` setting of the topic has to be set large enough as well. If you let the data loader to manage the topic (default), then its max message size is set to 100M by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb465c-5adb-455d-b9fb-a29208b4daa3",
   "metadata": {},
   "source": [
    "### Configure Kafka\n",
    "The Kafka cluster information is to be provided to the `.gds.configureKafka` function. Once configured, the settings will be shared with all newly created data loaders and no need to set up Kafka for each loader. A few important parameters to this function are:\n",
    "* `kafka_address`: the only required parameter for obvious reason. \n",
    "* `kafka_topic`: name of the topic to use. If it doesn't exist, the data loader will create it for you provided it has the permission. If it is not given, a topic with name like `tg_randomString` will be generated.\n",
    "* `kafka_security_protocol`: If authentication is required, `SSL`, `SASL_PLAINTEXT`, `SASL_SSL` are supported as security protocal. \n",
    "* `kafka_sasl_mechanism`: For the `SASL` protocal, mechanisms `PLAIN` and `GSSAPI` are supported. \n",
    "\n",
    "Please see the [doc](https://docs.tigergraph.com/pytigergraph/current/gds/gds#_configurekafka) for detailed settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e472d752-f2b9-4029-93e5-f23bf21d1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.gds.configureKafka(\n",
    "    kafka_address=\"127.0.0.1:9092\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22306c04-a113-46da-ad88-5b5d4c9deb88",
   "metadata": {},
   "source": [
    "### Load subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae1a869d-6b10-4f48-8fae-adc757e757cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:kafka.coordinator.consumer:group_id is None: disabling auto-commit.\n",
      "ERROR:kafka.conn:<BrokerConnection node_id=0 host=34.168.46.139:9092 <connected> [IPv4 ('34.168.46.139', 9092)]>: socket disconnected\n",
      "WARNING:kafka.client:Node 0 connection failed -- refreshing metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60.1 ms, sys: 3.93 ms, total: 64 ms\n",
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neighbor_loader = conn.gds.neighborLoader(\n",
    "    batch_size=16,\n",
    "    num_neighbors = 10,\n",
    "    num_hops =2,\n",
    "    v_in_feats = [\"x\"],\n",
    "    v_out_labels = [\"y\"],\n",
    "    v_extra_feats = [\"train_mask\", \"val_mask\", \"test_mask\"],\n",
    "    e_in_feats=[\"time\"],\n",
    "    e_out_labels=[],\n",
    "    e_extra_feats=[\"is_train\", \"is_val\"],\n",
    "    output_format = \"PyG\",\n",
    "    shuffle=True,\n",
    "    filter_by=\"train_mask\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d375539a-7b5c-4fe9-ab3e-53a78c9a2845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "Data(edge_index=[2, 380], edge_feat=[380], is_train=[380], is_val=[380], x=[257, 1433], y=[257], train_mask=[257], val_mask=[257], test_mask=[257], is_seed=[257])\n",
      "----Batch 1----\n",
      "Data(edge_index=[2, 413], edge_feat=[413], is_train=[413], is_val=[413], x=[243, 1433], y=[243], train_mask=[243], val_mask=[243], test_mask=[243], is_seed=[243])\n",
      "----Batch 2----\n",
      "Data(edge_index=[2, 358], edge_feat=[358], is_train=[358], is_val=[358], x=[212, 1433], y=[212], train_mask=[212], val_mask=[212], test_mask=[212], is_seed=[212])\n",
      "----Batch 3----\n",
      "Data(edge_index=[2, 468], edge_feat=[468], is_train=[468], is_val=[468], x=[298, 1433], y=[298], train_mask=[298], val_mask=[298], test_mask=[298], is_seed=[298])\n",
      "----Batch 4----\n",
      "Data(edge_index=[2, 406], edge_feat=[406], is_train=[406], is_val=[406], x=[266, 1433], y=[266], train_mask=[266], val_mask=[266], test_mask=[266], is_seed=[266])\n",
      "----Batch 5----\n",
      "Data(edge_index=[2, 353], edge_feat=[353], is_train=[353], is_val=[353], x=[242, 1433], y=[242], train_mask=[242], val_mask=[242], test_mask=[242], is_seed=[242])\n",
      "----Batch 6----\n",
      "Data(edge_index=[2, 427], edge_feat=[427], is_train=[427], is_val=[427], x=[302, 1433], y=[302], train_mask=[302], val_mask=[302], test_mask=[302], is_seed=[302])\n",
      "----Batch 7----\n",
      "Data(edge_index=[2, 377], edge_feat=[377], is_train=[377], is_val=[377], x=[246, 1433], y=[246], train_mask=[246], val_mask=[246], test_mask=[246], is_seed=[246])\n",
      "----Batch 8----\n",
      "Data(edge_index=[2, 205], edge_feat=[205], is_train=[205], is_val=[205], x=[150, 1433], y=[150], train_mask=[150], val_mask=[150], test_mask=[150], is_seed=[150])\n",
      "CPU times: user 1.53 s, sys: 58 ms, total: 1.59 s\n",
      "Wall time: 30.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(neighbor_loader):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aedd4f5-fdba-4da7-88e8-0a853d40221d",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "\n",
    "When this notebook is shutdown or the neighbor_loader object is garbage collected, the Kafka topic created by this loader should be deleted automatically. However, you can call the `.stop()` member function to manually delete the topic. It also resets the loader and closes the backgroud threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ec78f44-7247-43fa-8f3b-d21a3bc495ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_loader.stop(remove_topics=True)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m81"
  },
  "interpreter": {
   "hash": "96daeecb52bbbb8e3aef04d2f9c6a1e01f271d07cea30059f3c558ef00b717d2"
  },
  "kernelspec": {
   "display_name": "pyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
